{
  "task": "qa",
  "dataset": "jsonl",
  "size": 2,
  "metrics": {
    "exact_match": {
      "accuracy": 0.0
    },
    "sacrebleu": {
      "error": "sacrebleu not installed. Install with 'pip install -e .[metrics]'"
    },
    "bertscore": {
      "error": "bert-score not installed. Install with 'pip install -e .[metrics]'"
    }
  },
  "adapter": "echo",
  "seed": 0,
  "timing": {
    "avg_latency_ms": 0.0004169996827840805,
    "total_seconds": 0.0002554170205257833,
    "throughput_eps": 7830.331729196991
  },
  "manifest": {
    "timestamp": "2025-08-08T12:59:01",
    "openeval_version": "0.0.1",
    "python": {
      "version": "3.12.7",
      "executable": "/Users/rsainju/Research/1_Research_Personal/untitled folder/.venv/bin/python3"
    },
    "platform": {
      "system": "Darwin",
      "release": "24.6.0",
      "machine": "arm64"
    },
    "packages": {
      "fastapi": "0.116.1",
      "jinja2": "3.1.6",
      "numpy": "2.3.2",
      "pandas": "2.3.1"
    },
    "adapter": {
      "name": "echo",
      "class": "openeval.adapters.echo.EchoAdapter"
    },
    "task": {
      "name": "qa",
      "class": "openeval.tasks.qa.QATask"
    }
  },
  "dataset_path": "examples/qa_toy.jsonl",
  "dataset_hash_sha256": "9c52486013430898a086358be77233b1d6d990c776d7bd9ce9f9c5eedbf72540",
  "records": [
    {
      "id": "1",
      "input": "What is 2+2?",
      "reference": "4",
      "prediction": "Answer the question concisely.",
      "latency_ms": 0.0005420297384262085
    },
    {
      "id": "2",
      "input": "Capital of France?",
      "reference": "Paris",
      "prediction": "Answer the question concisely.",
      "latency_ms": 0.0002919696271419525
    }
  ],
  "spec_path": "examples/qa_metrics_spec.json",
  "spec_hash_sha256": "21966537231b2aec5d13b477d5638e92a0f3f54d179d1904327864d1723d6f0c",
  "run_name": "metrics demo"
}