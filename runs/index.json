{
  "runs": [
    {
      "task": "qa",
      "dataset": "jsonl",
      "size": 2,
      "metrics": {
        "exact_match": {
          "accuracy": 0.0
        },
        "sacrebleu": {
          "error": "sacrebleu not installed. Install with 'pip install -e .[metrics]'"
        },
        "bertscore": {
          "error": "bert-score not installed. Install with 'pip install -e .[metrics]'"
        }
      },
      "adapter": "echo",
      "seed": 0,
      "timing": {
        "avg_latency_ms": 0.00027101486921310425,
        "total_seconds": 6.0582999140024185e-05,
        "throughput_eps": 33012.56174818026
      },
      "manifest": {
        "timestamp": "2025-08-08T12:06:44",
        "openeval_version": "0.0.1",
        "python": {
          "version": "3.12.7",
          "executable": "/Users/rsainju/Research/1_Research_Personal/untitled folder/.venv/bin/python3"
        },
        "platform": {
          "system": "Darwin",
          "release": "24.6.0",
          "machine": "arm64"
        },
        "packages": {
          "fastapi": "0.116.1",
          "jinja2": "3.1.6",
          "numpy": "2.3.2",
          "pandas": "2.3.1"
        },
        "adapter": {
          "name": "echo",
          "class": "openeval.adapters.echo.EchoAdapter"
        },
        "task": {
          "name": "qa",
          "class": "openeval.tasks.qa.QATask"
        }
      },
      "dataset_path": "examples/qa_toy.jsonl",
      "dataset_hash_sha256": "9c52486013430898a086358be77233b1d6d990c776d7bd9ce9f9c5eedbf72540",
      "records": [
        {
          "id": "1",
          "input": "What is 2+2?",
          "reference": "4",
          "prediction": "Answer the question concisely.",
          "latency_ms": 0.000292027834802866
        },
        {
          "id": "2",
          "input": "Capital of France?",
          "reference": "Paris",
          "prediction": "Answer the question concisely.",
          "latency_ms": 0.0002500019036233425
        }
      ],
      "_file": "20250808-120644.json"
    },
    {
      "task": "qa",
      "dataset": "csv",
      "size": 2,
      "metrics": {
        "exact_match": {
          "accuracy": 0.0
        },
        "token_f1": {
          "f1": 0.0
        }
      },
      "adapter": "echo",
      "seed": 0,
      "timing": {
        "avg_latency_ms": 0.00043748877942562103,
        "total_seconds": 0.00037349999183788896,
        "throughput_eps": 5354.752459721778
      },
      "manifest": {
        "timestamp": "2025-08-08T12:10:32",
        "openeval_version": "0.0.1",
        "python": {
          "version": "3.12.7",
          "executable": "/Users/rsainju/Research/1_Research_Personal/untitled folder/.venv/bin/python3"
        },
        "platform": {
          "system": "Darwin",
          "release": "24.6.0",
          "machine": "arm64"
        },
        "packages": {
          "fastapi": "0.116.1",
          "jinja2": "3.1.6",
          "numpy": "2.3.2",
          "pandas": "2.3.1"
        },
        "adapter": {
          "name": "echo",
          "class": "openeval.adapters.echo.EchoAdapter"
        },
        "task": {
          "name": "qa",
          "class": "openeval.tasks.qa.QATask"
        }
      },
      "dataset_path": "examples/qa_toy.csv",
      "dataset_hash_sha256": "2f15c34ef7c3936cfa5fb3373de1f2cd52f50f08052488329e7f50eaba05b19c",
      "records": [
        {
          "id": "1",
          "input": "What is 2+2?",
          "reference": "4",
          "prediction": "Answer the question concisely.",
          "latency_ms": 0.0005830079317092896
        },
        {
          "id": "2",
          "input": "Capital of France?",
          "reference": "Paris",
          "prediction": "Answer the question concisely.",
          "latency_ms": 0.0002919696271419525
        }
      ],
      "_file": "20250808-121032.json"
    },
    {
      "task": "qa",
      "dataset": "jsonl",
      "size": 2,
      "metrics": {
        "exact_match": {
          "accuracy": 0.0
        },
        "sacrebleu": {
          "error": "sacrebleu not installed. Install with 'pip install -e .[metrics]'"
        },
        "bertscore": {
          "error": "bert-score not installed. Install with 'pip install -e .[metrics]'"
        }
      },
      "adapter": "echo",
      "seed": 0,
      "timing": {
        "avg_latency_ms": 0.0004169996827840805,
        "total_seconds": 0.0002554170205257833,
        "throughput_eps": 7830.331729196991
      },
      "manifest": {
        "timestamp": "2025-08-08T12:59:01",
        "openeval_version": "0.0.1",
        "python": {
          "version": "3.12.7",
          "executable": "/Users/rsainju/Research/1_Research_Personal/untitled folder/.venv/bin/python3"
        },
        "platform": {
          "system": "Darwin",
          "release": "24.6.0",
          "machine": "arm64"
        },
        "packages": {
          "fastapi": "0.116.1",
          "jinja2": "3.1.6",
          "numpy": "2.3.2",
          "pandas": "2.3.1"
        },
        "adapter": {
          "name": "echo",
          "class": "openeval.adapters.echo.EchoAdapter"
        },
        "task": {
          "name": "qa",
          "class": "openeval.tasks.qa.QATask"
        }
      },
      "dataset_path": "examples/qa_toy.jsonl",
      "dataset_hash_sha256": "9c52486013430898a086358be77233b1d6d990c776d7bd9ce9f9c5eedbf72540",
      "records": [
        {
          "id": "1",
          "input": "What is 2+2?",
          "reference": "4",
          "prediction": "Answer the question concisely.",
          "latency_ms": 0.0005420297384262085
        },
        {
          "id": "2",
          "input": "Capital of France?",
          "reference": "Paris",
          "prediction": "Answer the question concisely.",
          "latency_ms": 0.0002919696271419525
        }
      ],
      "spec_path": "examples/qa_metrics_spec.json",
      "spec_hash_sha256": "21966537231b2aec5d13b477d5638e92a0f3f54d179d1904327864d1723d6f0c",
      "run_name": "metrics demo",
      "_file": "20250808-125901.json"
    }
  ]
}